{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persiapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../../Data/wbc.csv'  # Make sure this file is in the same directory as your script\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 'id' and 'Unnamed: 32' columns.\n",
      "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0         M        17.99         10.38          122.80     1001.0   \n",
      "1         M        20.57         17.77          132.90     1326.0   \n",
      "2         M        19.69         21.25          130.00     1203.0   \n",
      "3         M        11.42         20.38           77.58      386.1   \n",
      "4         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove the 'id' and 'Unnamed: 32' columns (which is mostly empty)\n",
    "data = data.drop(columns=['id', 'Unnamed: 32'])\n",
    "print(\"Removed 'id' and 'Unnamed: 32' columns.\")\n",
    "print(data.head())  # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 'diagnosis' column.\n",
      "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          1        17.99         10.38          122.80     1001.0   \n",
      "1          1        20.57         17.77          132.90     1326.0   \n",
      "2          1        19.69         21.25          130.00     1203.0   \n",
      "3          1        11.42         20.38           77.58      386.1   \n",
      "4          1        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Encode the 'diagnosis' column (M -> 1, B -> 0)\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "print(\"Encoded 'diagnosis' column.\")\n",
    "print(data.head())  # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized numerical columns.\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
      "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
      "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
      "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
      "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          3.283515        2.652874             2.532475       2.217515   \n",
      "1         -0.487072       -0.023846             0.548144       0.001392   \n",
      "2          1.052926        1.363478             2.037231       0.939685   \n",
      "3          3.402909        1.915897             1.451707       2.867383   \n",
      "4          0.539340        1.371011             1.428493      -0.009560   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
      "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
      "2               -0.398008  ...      1.511870      -0.023974         1.347475   \n",
      "3                4.910919  ...     -0.281464       0.133984        -0.249939   \n",
      "4               -0.562450  ...      1.298575      -1.466770         1.338539   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0    2.001237          1.307686           2.616665         2.109526   \n",
      "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
      "2    1.456285          0.527407           1.082932         0.854974   \n",
      "3   -0.550021          3.394275           3.893397         1.989588   \n",
      "4    1.220724          0.220556          -0.313395         0.613179   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              2.296076        2.750622                 1.937015  \n",
      "1              1.087084       -0.243890                 0.281190  \n",
      "2              1.955000        1.152255                 0.201391  \n",
      "3              2.175786        6.046041                 4.935010  \n",
      "4              0.729259       -0.868353                -0.397100  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Standardize all numerical columns (excluding the diagnosis column)\n",
    "X = data.drop(columns=['diagnosis'])  # All features\n",
    "y = data['diagnosis']  # Target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "print(\"Standardized numerical columns.\")\n",
    "print(X_scaled.head())  # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah label data asli:\n",
      "diagnosis\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Jumlah label data train:\n",
      "diagnosis\n",
      "0    285\n",
      "1    170\n",
      "Name: count, dtype: int64\n",
      "Jumlah label data val:\n",
      "diagnosis\n",
      "0    36\n",
      "1    21\n",
      "Name: count, dtype: int64\n",
      "Jumlah label data test:\n",
      "diagnosis\n",
      "0    36\n",
      "1    21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Stratified split for train and test data (80:20 ratio)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_unseen, y_train, y_unseen = train_test_split(X_scaled, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_unseen, y_unseen, test_size=0.5, random_state=0, stratify=y_unseen)\n",
    "\n",
    "print(f'Jumlah label data asli:\\n{y.value_counts()}')\n",
    "print(f'Jumlah label data train:\\n{y_train.value_counts()}')\n",
    "print(f'Jumlah label data val:\\n{y_val.value_counts()}')\n",
    "print(f'Jumlah label data test:\\n{y_test.value_counts()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
